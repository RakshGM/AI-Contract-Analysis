"""
Performance test script for contract analysis
"""

import time
from ai_agents.main import run
from ai_agents.context_cache import clear_context_cache

def test_analysis_performance():
    """Test the performance of contract analysis"""
    
    query = "Analyze the contract for legal, compliance, financial, and operational risks"
    
    print("=" * 70)
    print("CONTRACT ANALYSIS PERFORMANCE TEST")
    print("=" * 70)
    print(f"\nQuery: {query}")
    print("\nOptimizations applied:")
    print("  ‚úì Parallel agent execution (4 agents run concurrently)")
    print("  ‚úì Cached embedding model (avoids reloading)")
    print("  ‚úì Shared context cache (single retrieval for all agents)")
    print("  ‚úì Reduced chunks from 3 to 2 (33% less data)")
    print("\n" + "-" * 70)
    
    # Clear cache for fair test
    clear_context_cache()
    
    # Run analysis
    print("\nüöÄ Starting analysis...")
    start_time = time.time()
    
    result = run(query)
    
    end_time = time.time()
    execution_time = end_time - start_time
    
    print("\n" + "=" * 70)
    print(f"‚úÖ ANALYSIS COMPLETE")
    print("=" * 70)
    print(f"\n‚è±Ô∏è  Total execution time: {execution_time:.2f} seconds")
    print(f"‚ö° Average time per agent: {execution_time/4:.2f} seconds")
    
    # Estimate improvements
    print("\n" + "-" * 70)
    print("ESTIMATED IMPROVEMENTS:")
    print("-" * 70)
    print("  Previous: ~28-30 seconds (with 2 chunks)")
    print(f"  Current:  ~{execution_time:.0f} seconds (with 1 chunk + optimized tokens)")
    print(f"  Speed improvement: ~{28.5/execution_time:.1f}x faster than previous version")
    print(f"  Overall improvement: ~{150/execution_time:.1f}x faster than sequential baseline")
    print("\n  Optimizations Applied:")
    print("    ‚Ä¢ Reduced chunks: 2 ‚Üí 1 (50% reduction)")
    print("    ‚Ä¢ Reduced max_tokens: 4096 ‚Üí 2048 per agent")
    print("    ‚Ä¢ Temperature reduced: 0.3 ‚Üí 0.2 (faster)")
    print("    ‚Ä¢ Skipped structured extraction")
    print("    ‚Ä¢ Parallel execution (4 agents concurrent)")
    print("    ‚Ä¢ Cached embedding model")
    print("    ‚Ä¢ Shared context cache")
    print("\n" + "=" * 70)
    
    return result

if __name__ == "__main__":
    test_analysis_performance()
